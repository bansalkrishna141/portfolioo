<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Project 2: Saksham</title>
    <link rel="stylesheet" href="styles.css">
</head>
<body>
    <header>
        <div class="topnav">
            <a href="index.html">Home</a>
            <a href="project1.html">Rakshik</a>
            <a href="project3.html">Saksham</a>
            <a href="project4.html">Advance Security System</a>
        </div>
        <div class="header-content">
            <h1>Project 2: Saksham</h1>
            <p>Ears to the Deaf and Voices to the Mute</p>
        </div>
    </header>

    <main class="container">
        <section>
            <h2>Overview</h2>
            <p>"Saksham" is a transformative project aimed at bridging the communication gap for individuals with hearing and speech impairments. By leveraging Raspberry Pi and advanced machine learning techniques, Saksham converts sign language into text and speech, as well as converts spoken language into text.</p>
            <p>This dual functionality empowers the mute to communicate verbally and provides the deaf with a means to understand spoken language in real-time.</p>
        </section>

        <section>
            <h2>Features</h2>
            <ul>
                <li>Sign Language to Text: Uses a camera and machine learning models to interpret sign language gestures and convert them into text.</li>
                <li>Text to Speech: Converts the interpreted text into speech, allowing mute individuals to communicate verbally.</li>
                <li>Speech to Text: Utilizes speech recognition to transcribe spoken words into text, aiding deaf individuals in understanding conversations.</li>
                <li>User-Friendly Interface: Simple and intuitive interface for seamless interaction and communication.</li>
                <li>Portable and Affordable: Built using Raspberry Pi, making it a cost-effective and portable solution.</li>
            </ul>
        </section>

        <section>
            <h2>Technologies Used</h2>
            <ul>
                <li>Raspberry Pi: Compact and affordable hardware platform for running the software.</li>
                <li>Machine Learning: Algorithms for recognizing sign language gestures and speech patterns.</li>
                <li>Computer Vision: Camera integration to capture sign language gestures.</li>
                <li>Speech Recognition: Software for transcribing spoken language into text.</li>
                <li>Text-to-Speech (TTS): Converts text into spoken words using TTS engines.</li>
            </ul>
        </section>

        <section>
            <h2>Impact and Statistics</h2>
            <p>Global Impact: According to the World Health Organization (WHO), over 5% of the world’s population, or 430 million people, require rehabilitation to address their ‘disabling’ hearing loss. "Saksham" aims to assist a significant portion of this population.</p>
        </section>
    </main>

    <footer>
        <p>&copy; 2024 Krishna Bansal</p>
    </footer>
</body>
</html>
